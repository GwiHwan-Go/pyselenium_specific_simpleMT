{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jieba\n",
    "# !pip install emoji\n",
    "import jieba\n",
    "def segmentate_sentence(sent):\n",
    "    \"\"\"\n",
    "    word segmentation with jieba\n",
    "    ref : https://github.com/fxsjy/jieba\n",
    "    Args :\n",
    "        sent(Str) : a sentence without segmentation, e.g \"Iloveyou\"\n",
    "    Output :\n",
    "        sent(str) : segmentated sentence, e.g \"I love you\"\n",
    "    \"\"\"\n",
    "    # sent = clean(sent)\n",
    "    seg_list = jieba.lcut(sent, cut_all=False)\n",
    "    \n",
    "    seg_list = [i for i in seg_list if i!=\" \"]\n",
    "    return seg_list\n",
    "    \n",
    "def clean(x):\n",
    "    \"\"\"clean tweets\n",
    "    :param: a tweet (str)\n",
    "    :return a preprocessed tweet (str)\n",
    "    \"\"\"\n",
    "    import emoji\n",
    "    from collections import Counter\n",
    "    import re\n",
    "    emojis = ''.join(emoji.UNICODE_EMOJI.keys())\n",
    "    pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-힣{emojis}]+')\n",
    "    username_pattern = re.compile(\n",
    "        r\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)\")\n",
    "    url_pattern = re.compile(\n",
    "        r\"[-a-zA-Z0-9@:%_\\+.~#?&//=]{2,256}\\.[a-z]{2,4}\\b(\\/[-a-zA-Z0-9@:%_\\+.~#?&//=]*)?\")\n",
    "\n",
    "    chinese_pattern=re.compile(r\"[^\\u4e00-\\u9fa5]+\")\n",
    "#     x = username_pattern.sub('', x)\n",
    "#     x = url_pattern.sub('', x)\n",
    "    x = chinese_pattern.sub('', x)\n",
    "#     x = re.sub(r'[0-9]+', '', x)\n",
    "#     table = x.maketrans({ '/': ' ',  '#': ' ', '@':' ', ':':' '})\n",
    "#     x = x.translate(table)\n",
    "    x = re.sub(pattern, '', x)\n",
    "#     x = re.sub(r\"[^a-zA-Z0-9]\",\"\",x) # 특수문자 제거\n",
    "    x = x.strip()\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from xlsx to csv\n",
    "def make_user_dict(xlsx_path, path) :\n",
    "    \"\"\"\n",
    "    make a custom dictionary for jieba\n",
    "    It makes a txt file to communicate with jieba\n",
    "    xlsx_path : A path of dictionary\n",
    "    path : A result path of dictionary\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(xlsx_path)\n",
    "    with open(path, \"w\") as f :\n",
    "        f.writelines('\\n'.join(df.loc[:,'words']))\n",
    "    f.close()\n",
    "    \n",
    "def add_words(raw_paths, existing_data=None) :\n",
    "    \"\"\"\n",
    "    add new data with existing data\n",
    "    input :\n",
    "        raw_paths : list of path in train_data folder\n",
    "        existing_data : dataframe - existing data, if not given, it initalize the dataset\n",
    "    output :\n",
    "        set of words\n",
    "    \"\"\"\n",
    "    # # !pip install googletrans==3.1.0a0\n",
    "    # # ref) https://stackoverflow.com/questions/52455774/googletrans-stopped-working-with-error-nonetype-object-has-no-attribute-group\n",
    "    # # ref) https://pypi.org/project/googletrans/\n",
    "    # from googletrans import Translator\n",
    "    # gmt = Translator()\n",
    "    # gmt.translate(word, dest='ko').text\n",
    "\n",
    "    bag_of_words = []\n",
    "    cnt_words = []\n",
    "    meanings = []\n",
    "    positions = []\n",
    "\n",
    "    if existing_data is not None :\n",
    "        bag_of_words = list(existing_data.loc[:,'words'])\n",
    "        cnt_words = list(existing_data.loc[:,'cnt'])\n",
    "        meanings = list(existing_data.loc[:,'meaning'])\n",
    "        positions = list(existing_data.loc[:,'position'])\n",
    "\n",
    "    for path in raw_paths :\n",
    "        df = pd.read_csv(f\"train_data/{path}.csv\")\n",
    "\n",
    "        for row in tqdm(range(df.shape[0])) :\n",
    "            for word in segmentate_sentence(df['English title'][row]) :\n",
    "                if word in bag_of_words :\n",
    "                    cnt_words[bag_of_words.index(word)]+=1\n",
    "                else :\n",
    "                    bag_of_words.append(word)\n",
    "                    cnt_words.append(1)\n",
    "                    res = translate(word)\n",
    "                    meanings.append(json.loads(res)['message']['result']['translatedText'])\n",
    "                    positions.append(\"\")\n",
    "\n",
    "    df = pd.DataFrame(list(zip(bag_of_words, meanings, positions, cnt_words)),columns =['words', 'meaning', 'position','cnt'])\n",
    "    return df.sort_values(by='cnt', ascending=False).reset_index(drop=True)\n",
    "\n",
    "def translate(target) :\n",
    "    import os\n",
    "    import sys\n",
    "    import urllib.request\n",
    "    # from Local import client_id, client_secret\n",
    "    client_id = \"sy3GuTVVRhzvp2xC8vVM\" # 개발자센터에서 발급받은 Client ID 값\n",
    "    client_secret = \"D1CqkDNhAq\" \n",
    "    encText = urllib.parse.quote(target)\n",
    "    data = \"source=zh-CN&target=ko&text=\" + encText\n",
    "    url = \"https://openapi.naver.com/v1/papago/n2mt\"\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request, data=data.encode(\"utf-8\"))\n",
    "    rescode = response.getcode()\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "        return response_body.decode('utf-8')\n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "\n",
    "def retrain(txt_path, ref_path) :\n",
    "    \"\"\"\n",
    "    update the dictionary with txt file.\n",
    "    if line startswith '`' : update with this\n",
    "    input :\n",
    "        txt_path : updated contents\n",
    "        ref_path : reference dictionary's path\n",
    "    \"\"\"\n",
    "    print(\"#####Retrain Started#####\")\n",
    "    dic = defaultdict(str)\n",
    "    reference= pd.read_excel(ref_path)\n",
    "    reference = reference.set_index('words', drop=True)\n",
    "    changed=[]\n",
    "    with open(txt_path, \"r\") as f:\n",
    "        li = f.readlines()\n",
    "        li = [i.strip() for i in li]\n",
    "\n",
    "    for word in li :\n",
    "        if word.startswith('---') or word.startswith('result'):\n",
    "            continue\n",
    "        if word.startswith('₩'):\n",
    "            try :\n",
    "                key, item = word.split(',')\n",
    "                dic[key.strip()[1:]] = item.strip()\n",
    "            except :\n",
    "                pass\n",
    "\n",
    "    for key in dic.keys() :\n",
    "        print(key)\n",
    "        if key in reference.index :\n",
    "            if reference.loc[key, 'meaning'] != dic[key] :\n",
    "                reference.loc[key, 'meaning'] = dic[key]\n",
    "                changed.append(key)\n",
    "        else :\n",
    "            reference.loc[key] = [dic[key], 0,1]\n",
    "            changed.append(key)\n",
    "    for key in changed :            \n",
    "        print(f\"{key} -> {reference.loc[key]['meaning']}\")\n",
    "\n",
    "    print(f\"data has been updated {len(changed)} times\")\n",
    "    reference.to_excel(ref_path)  \n",
    "    print(\"#####Retrain Ended#####\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meaning</th>\n",
       "      <th>position</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>新款</th>\n",
       "      <td>신상</td>\n",
       "      <td>9</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>女</th>\n",
       "      <td>여성</td>\n",
       "      <td>5</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>上衣</th>\n",
       "      <td>상의</td>\n",
       "      <td>8</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>夏季</th>\n",
       "      <td>여름</td>\n",
       "      <td>9</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>生活在左</th>\n",
       "      <td>A Life On the Left</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>植物</th>\n",
       "      <td>천연</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>染</th>\n",
       "      <td>염색</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>梨型</th>\n",
       "      <td>D자</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>宫廷</th>\n",
       "      <td>유럽 궁전</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  meaning position  cnt\n",
       "words                                  \n",
       "新款                     신상        9  232\n",
       "2022                 2022        9  200\n",
       "女                      여성        5  189\n",
       "上衣                     상의        8  110\n",
       "夏季                     여름        9  101\n",
       "...                   ...      ...  ...\n",
       "生活在左   A Life On the Left        0    1\n",
       "植物                     천연        0    1\n",
       "染                      염색        0    1\n",
       "梨型                     D자        0    1\n",
       "宫廷                  유럽 궁전        0    1\n",
       "\n",
       "[1390 rows x 3 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Mark Position##\n",
    "reference= pd.read_excel(train_data)\n",
    "reference = reference.set_index('words', drop=True)\n",
    "reference = reference.dropna(axis=0)\n",
    "reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "夏季 여름 --> 11\n",
      "春季 봄철 --> 11\n",
      "早春 이른 봄 --> 11\n",
      "春秋 봄/가을 --> 11\n",
      "春装 봄옷 --> 11\n",
      "春夏 봄/여름 --> 11\n",
      "夏 여름 --> 11\n",
      "春 봄 --> 11\n",
      "秋冬 가을/겨울 --> 11\n",
      "春款 봄 스타일 --> 11\n",
      "冬季 겨울 --> 11\n",
      "秋 가을 --> 11\n",
      "夏日 여름 --> 11\n",
      "春秋季 봄/가을 --> 11\n",
      "春天 봄 --> 11\n",
      "秋季 가을철 --> 11\n",
      "春夏季 봄여름 --> 11\n",
      "冬装 겨울옷 --> 11\n",
      "显瘦春 날씬해 보이는 봄 --> 11\n",
      "夏大码 여름 빅 사이즈 --> 11\n",
      "冬 겨울 --> 11\n",
      "夏天 여름 --> 11\n",
      "秋装 가을 옷차림 --> 11\n",
      "初秋 초가을 --> 11\n"
     ]
    }
   ],
   "source": [
    "#######Add position of words which are in the given set#####\n",
    "def give_position(set_of_words, position, reference) :\n",
    "    \"\"\"\n",
    "    Add position information to reference file\n",
    "    \"\"\"\n",
    "    for idx in reference.index :\n",
    "        word = reference.loc[idx,'meaning']\n",
    "        word = str(word)\n",
    "        flag=False\n",
    "        for chaidx in range(len(str(word))) :\n",
    "            if word[chaidx] in set_of_words :\n",
    "                flag=True\n",
    "            if chaidx != len(word)-1 : ### You should renew here\n",
    "                if word[chaidx:chaidx+2] in set_of_words :\n",
    "                    flag=True\n",
    "        if flag :\n",
    "            reference.loc[idx,'position'] = position\n",
    "            print(idx, reference.loc[idx,'meaning'], \"-->\", position)\n",
    "    \n",
    "    return reference\n",
    "\n",
    "set_of_words = ['봄','여름','가을','겨울']\n",
    "position = 11\n",
    "reference= pd.read_excel(train_data)\n",
    "reference = reference.set_index('words', drop=True)\n",
    "reference = reference.dropna(axis=0)\n",
    "reference = give_position(set_of_words, position, reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####Retrain Started#####\n",
      "月牙\n",
      "大连东越\n",
      "逃离\n",
      "地球\n",
      "御姐\n",
      "卡农\n",
      "月牙 -> Yueya\n",
      "大连东越 -> Dalian-dongyue\n",
      "逃离 -> TAOLI\n",
      "地球 -> DIQIU\n",
      "御姐 -> 걸크러쉬\n",
      "卡农 -> Qiaonong\n",
      "data has been updated 6 times\n",
      "#####Retrain Ended#####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:12<00:35,  2.34it/s]"
     ]
    }
   ],
   "source": [
    "##Start Working##\n",
    "def forward(data_path, train_data, user_dict, start) :\n",
    "    df = pd.read_csv(data_path)\n",
    "    #########LOAD TRAINED SECTION##########\n",
    "    make_user_dict(train_data, user_dict)\n",
    "    jieba.load_userdict(user_dict) # load customized dictionary\n",
    "    reference= pd.read_excel(train_data)\n",
    "    reference = reference.set_index('words', drop=True)\n",
    "    reference = reference.dropna(axis=0)\n",
    "    #########LOAD TRAINED SECTION##########\n",
    "    with open(\"./working/auto.txt\", \"w\") as h :\n",
    "        with open(\"./working/new_data.txt\", \"w\")as g :\n",
    "            for row in tqdm(range(start, df.shape[0])) :\n",
    "                ###################Generating Section###########################\n",
    "                sentence = segmentate_sentence(df['English title'][row])\n",
    "                translated = []\n",
    "                buff = defaultdict(str)\n",
    "                key_words= ['2022', '신상', '2022신상', '22', '20', '년'] ## For Extra section\n",
    "                season=\"\"\n",
    "                new_flag=False\n",
    "                for word in segmentate_sentence(df['English title'][row]) :\n",
    "                    if word in reference.index :\n",
    "                        if reference.loc[word, 'position'] ==11 : ##Check Season\n",
    "                            season = reference.loc[word,'meaning']\n",
    "                        buff[word] = list(reference.loc[word, :])\n",
    "                        translated.append(str(buff[word][0]))\n",
    "                    else :\n",
    "                        res = translate(word)\n",
    "                        res = json.loads(res)['message']['result']['translatedText']\n",
    "                        # res = word\n",
    "                        buff[word] = [res,0,1]\n",
    "                        translated.append(buff[word][0])\n",
    "                ###################Generating Section###########################\n",
    "\n",
    "                ###################Extra Section###########################\n",
    "                    if new_flag==False :\n",
    "                        if buff[word][0] in key_words :        \n",
    "                            new_flag=True\n",
    "\n",
    "                translated = [word for word in translated if (word not in key_words)]\n",
    "                ###################Extra Section###########################\n",
    "\n",
    "                ###################Writing Section###########################\n",
    "                h.write(f\"{row+1}.\\n\")\n",
    "                h.write(f\"{' '.join(sentence)}\\n\")\n",
    "                h.write(f\"{' '.join(translated)}, \")\n",
    "                if new_flag :\n",
    "                    if season == \"\" :\n",
    "                        h.write(f\"2022 신상\\n\")\n",
    "                    else :\n",
    "                        h.write(f\"2022 {season} 신상\\n\")\n",
    "                else :\n",
    "                    h.write(\"\\n\")\n",
    "                g.write(f\"\\n-------------------{row+1}------------\\n\")\n",
    "                for key, item in buff.items() :\n",
    "                    g.write(f\"{key}, {item[0]}\\n\")\n",
    "                ###################Writing Section###########################\n",
    "        g.close()\n",
    "        print(\"auto.txt has successfully saved as ./working/auto.txt\")\n",
    "    h.close()\n",
    "    print(\"new_data.txt has successfully saved as ./working/new_data.txt\")\n",
    "    print(\"Everything has completed, Go to work\")\n",
    "\n",
    "data_path=\"working/work.csv\"\n",
    "train_data=\"./train_data/reference.xlsx\"\n",
    "user_dict=\"./train_data/userdict.txt\"\n",
    "\n",
    "retrain(\"./working/new_data.txt\", \"./train_data/reference.xlsx\")\n",
    "forward(data_path, train_data, user_dict, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meaning</th>\n",
       "      <th>position</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>新款</th>\n",
       "      <td>신상</td>\n",
       "      <td>9</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>女</th>\n",
       "      <td>여성</td>\n",
       "      <td>5</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>上衣</th>\n",
       "      <td>상의</td>\n",
       "      <td>8</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>夏季</th>\n",
       "      <td>여름</td>\n",
       "      <td>9</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>好看</th>\n",
       "      <td>스타일 좋은</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>纯欲</th>\n",
       "      <td>순수하면서도 섹시한</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>生活在左</th>\n",
       "      <td>A Life On the Left</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>植物</th>\n",
       "      <td>천연</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>染</th>\n",
       "      <td>염색</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  meaning position  cnt\n",
       "words                                  \n",
       "新款                     신상        9  232\n",
       "2022                 2022        9  200\n",
       "女                      여성        5  189\n",
       "上衣                     상의        8  110\n",
       "夏季                     여름        9  101\n",
       "...                   ...      ...  ...\n",
       "好看                 스타일 좋은        0    1\n",
       "纯欲             순수하면서도 섹시한        0    1\n",
       "生活在左   A Life On the Left        0    1\n",
       "植物                     천연        0    1\n",
       "染                      염색        0    1\n",
       "\n",
       "[1390 rows x 3 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating - word\n",
    "\n",
    "One hot encoding including position infos.\n",
    "\n",
    "meaning, category, position info\n",
    "\n",
    "1. give main meaning\n",
    "2. add meaning\n",
    "3. add position meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words - word - meaning - cate - \n",
    "1\n",
    "2\n",
    "3\n",
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Opn other files and save on this table too###\n",
    "###No overlap"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95cb90694882dadca987f5fb6182f3bb000d75c3a77cb8ddf9893f9283882476"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('py_selenium')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
